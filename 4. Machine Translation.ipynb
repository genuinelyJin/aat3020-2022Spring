{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80c87a7a",
   "metadata": {},
   "source": [
    "# Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518b10da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1CpsqOuuuB3I_PG5DbuqH1ssCFVerU46g\n",
      "To: /home/teo/userdata/sg-aat-3020/aat3020-2022Spring/nia-aihub-korean-english.zip\n",
      "100%|████████████████████████████████████████| 276M/276M [00:34<00:00, 8.06MB/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Download dataset (originally from NIA AI-Hub)\n",
    "'''\n",
    "\n",
    "!gdown 1CpsqOuuuB3I_PG5DbuqH1ssCFVerU46g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192d9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q nia-aihub-korean-english.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca202b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/.local/lib/python3.8/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/home/teo/.local/lib/python3.8/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/home/teo/.local/lib/python3.8/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/home/teo/.local/lib/python3.8/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = Path('nia_korean_english')\n",
    "data_list = sorted(list(dataset_dir.glob('*.xlsx')))\n",
    "for path in dataset_dir.glob('*.xlsx'):\n",
    "  df = pd.read_excel(path)\n",
    "  kor_text_path = path.parent / (path.stem+'_kor.txt') \n",
    "  eng_text_path = path.parent / (path.stem+'_eng.txt') \n",
    "  with open(kor_text_path, 'w', encoding='utf8') as f:\n",
    "      f.write('\\n'.join(df['원문']))\n",
    "  with open(eng_text_path, 'w', encoding='utf8') as f:\n",
    "      f.write('\\n'.join(df['번역문']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fbc2c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('nia_korean_english/1_구어체(1).xlsx'),\n",
       " PosixPath('nia_korean_english/1_구어체(2).xlsx'),\n",
       " PosixPath('nia_korean_english/2_대화체.xlsx'),\n",
       " PosixPath('nia_korean_english/3_문어체_뉴스(1)_200226.xlsx'),\n",
       " PosixPath('nia_korean_english/3_문어체_뉴스(2).xlsx'),\n",
       " PosixPath('nia_korean_english/3_문어체_뉴스(3).xlsx'),\n",
       " PosixPath('nia_korean_english/3_문어체_뉴스(4).xlsx'),\n",
       " PosixPath('nia_korean_english/4_문어체_한국문화.xlsx'),\n",
       " PosixPath('nia_korean_english/5_문어체_조례.xlsx'),\n",
       " PosixPath('nia_korean_english/6_문어체_지자체웹사이트.xlsx')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c767468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teo/.local/lib/python3.8/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = [pd.read_excel(path) for path in data_list[:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e9f316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff8b8786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000    Dogs, like dolphins and apes and parrots, can ...\n",
       "10001    If the dog still keeps on hiccuping, then it m...\n",
       "10002                                The dog will love it.\n",
       "10003                                He's a beautiful dog.\n",
       "10004                  I'm going to clean up the dog mess.\n",
       "10005    I just woke up from my luggage because of the ...\n",
       "10006    Knowing the meanings of the behaviors of pet d...\n",
       "10007    When individuals stay closely together, they c...\n",
       "10008    It is difficult to predict when each individua...\n",
       "10009    I believe a true society can be achieved only ...\n",
       "10010    For the first time in 100years since its incep...\n",
       "10011    What did frog do after knowing that a snake ea...\n",
       "10012     He turned into a frog and was bullied by people.\n",
       "10013    The character is a naughty personality who is ...\n",
       "10014    I thought he was always going get in trouble, ...\n",
       "10015    There are fireworks on the national foundation...\n",
       "10016    Not anyone or anything, look what you want to ...\n",
       "10017    The only scene filmed at Gaenari Apartment was...\n",
       "10018    The forsythia is a representative flower for t...\n",
       "10019    In concept, extent, and associated meaning lev...\n",
       "10020    Please review the concept and give us your opi...\n",
       "10021    After explaining the concept, solve the proble...\n",
       "10022    Dogs, different from cats, do not hide and cli...\n",
       "10023    When the dogs go out for a walk, they keep sniff.\n",
       "10024    Dogs usually straighten their tails to show th...\n",
       "10025    The dog was running around and lying on the sand.\n",
       "10026                     Dogs might shit in the elevator.\n",
       "10027    The dog didn't think about the value of the me...\n",
       "10028    Many people love dogs because it has strong lo...\n",
       "10029             Dogs lose their hair because they do it.\n",
       "10030         Dogs docile so they follow human with favor.\n",
       "10031    It's $110 per unit and could you give them to ...\n",
       "10032              The price of each unit is 1.26 dollars.\n",
       "10033                    Dogs can communicate like humans.\n",
       "10034           Dogs see humans as part of their families.\n",
       "10035    There are many different kinds of dogs that va...\n",
       "10036                     Dogs have good olfactory nerves.\n",
       "10037    Dogs are loyal to their owners and give them l...\n",
       "10038               Dogs seem to follow their owners well.\n",
       "10039                The Gaeddeong's ice meokbang was fun.\n",
       "10040               How long do you spend walking the dog?\n",
       "10041    As opening exhibitions became competitive all ...\n",
       "10042    Groups of ants can accomplish many difficult t...\n",
       "10043    What do ants, bees, pigeons and herring all ha...\n",
       "10044        Ants a good example of such bandying animals.\n",
       "10045    The ants have the excretion organs in the abdo...\n",
       "10046    Ants will live their lives, doing all the thin...\n",
       "10047            Ants never bend their course to an enemy.\n",
       "10048    In the case of ants, there appears to be no le...\n",
       "10049    The ant and the dove appreciated each others f...\n",
       "Name: 번역문, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['번역문'][10000:10050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f99ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = data_list[0]\n",
    "\n",
    "# kor_text_path = path.parent / (path.stem+'_kor.txt') \n",
    "# eng_text_path = path.parent / (path.stem+'_eng.txt') \n",
    "# with open(kor_text_path, 'w', encoding='utf8') as f:\n",
    "#     f.write('\\n'.join(df['원문']))\n",
    "# with open(eng_text_path, 'w', encoding='utf8') as f:\n",
    "#     f.write('\\n'.join(df['번역문']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df6e584",
   "metadata": {},
   "source": [
    "## Huggingface Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c6f1769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hugging_eng_32000/vocab.txt']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "tokenizer = BertWordPieceTokenizer(strip_accents=False, lowercase=False)\n",
    "\n",
    "# corpus_file   =  [str(path.parent / (path.stem + '_kor.txt')) for path in data_list[:2]]\n",
    "# output_dir   = Path('hugging_kor_%d'%(vocab_size))\n",
    "corpus_file   =  [str(path.parent / (path.stem + '_eng.txt')) for path in data_list[:2]]\n",
    "output_dir   = Path('hugging_eng_%d'%(vocab_size))\n",
    "\n",
    "vocab_size    = 32000  # Number of maximum size of the vocabulary\n",
    "limit_alphabet= 6000   \n",
    "output_dir   = Path('hugging_eng_%d'%(vocab_size))\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "min_frequency = 5 \n",
    "\n",
    "tokenizer.train(files=corpus_file,\n",
    "               vocab_size=vocab_size,\n",
    "               min_frequency=min_frequency,\n",
    "               limit_alphabet=limit_alphabet, \n",
    "               show_progress=True)\n",
    "\n",
    "tokenizer.save_model(str(output_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "410eb97a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 나는 친구에게 그 철학자의 책을 선물해 주겠다고 말했습니다. [SEP]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer_src = BertTokenizerFast.from_pretrained('hugging_kor_32000',\n",
    "                                                       strip_accents=False,\n",
    "                                                       lowercase=False) \n",
    "tokenizer_tgt = BertTokenizerFast.from_pretrained('hugging_eng_32000',\n",
    "                                                       strip_accents=False,\n",
    "                                                       lowercase=False) \n",
    "\n",
    "tokenized_data = tokenizer_src(df['원문'].iloc[10])\n",
    "print(tokenizer_src.decode(tokenized_data['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "340f55c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3390, 4172, 4347, 3]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ids = tokenizer_src(\"나는 학교에 갑니다\")['input_ids']\n",
    "tokenized_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b3ea831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 나는 학교에 갑니다 [SEP]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_src.decode(tokenized_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3acc83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SID                                                    5\n",
       "원문        6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.\n",
       "번역문    I would feel grateful to know how many stocks ...\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26964dcb",
   "metadata": {},
   "source": [
    "## Divide Train / Validate/ Test Set\n",
    "- using `np.random.choice`\n",
    "    - To always get the same random shuffling result, you have to use `np.random.seed()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b088f662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba4a138a",
   "metadata": {},
   "source": [
    "## Define Dataset\n",
    "- Each datasample has to return source sentence and target sentence\n",
    "- You need a Tokenizer to get the tokenized result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76933a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a9f0ec",
   "metadata": {},
   "source": [
    "## Define Collate function\n",
    "- After implementing Dataset, we have to declare DataLoader that groups several training samples as a single batch\n",
    "- However, we cannot batchify the melodies in straightforward way, because the length of each melody is different\n",
    "- In this problem, you will learn about how to handle sequences of different length as a batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456ff9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "This cell will make error, because the length of each sample is different to each other\n",
    "'''\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=8)\n",
    "batch = next(iter(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc533f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To handle that problem, you have to make your collate function \n",
    "'''\n",
    "def your_collate_function(raw_batch):\n",
    "  '''\n",
    "  You can make your own function to handle the batch\n",
    "  '''\n",
    "  \n",
    "  return raw_batch[0] # This returns the first melody of each batch. So it will avoid the error, but it doesn't do proper batchifying\n",
    "\n",
    "batch_size = 8\n",
    "raw_batch = [train_set[i] for i in range(batch_size)] # This is the input for the collate function\n",
    "batch = your_collate_function(raw_batch)\n",
    "\n",
    "'''\n",
    "This is what the 'collate_fn' does in DataLoader\n",
    "'''\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, collate_fn=your_collate_function)\n",
    "batch_by_loader = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22db0716",
   "metadata": {},
   "source": [
    "#### Pad Sequence and Pack Sequence\n",
    "In PyTorch, there are two ways to batchify a group of sequence with different length.\n",
    "- `torch.nn.utils.rnn.pad_sequence`\n",
    "    - This function takes list of tensors with different length and return padded sequence\n",
    "    - Padding is adding some constant number as a PAD token to match the length of short sequence to the maximum length\n",
    "        - e.g. If there are sequence of length (3,7,4), we can add 4 zeros to sequence with length 3, 3 zeros to sequence with length 4 to make them length 7\n",
    "    - In default, we use 0 for padding (zero padding)\n",
    "    - The result \n",
    "- `torch.nn.utils.rnn.pack_sequence`\n",
    "    - pad_sequence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8cce88",
   "metadata": {},
   "source": [
    "Cells below show the example of `pad_sequence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe229f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3., 27., 15.],\n",
       "        [ 2., 26., 14.],\n",
       "        [ 1., 25., 13.],\n",
       "        [ 0., 24., 12.],\n",
       "        [ 0., 23., 11.],\n",
       "        [ 0., 22., 10.],\n",
       "        [ 0., 21.,  0.],\n",
       "        [ 0., 20.,  0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence, PackedSequence\n",
    "short = torch.arange(3, -1, -1).float() # [3, 2, 1, 0]\n",
    "long = torch.arange(27,19, -1).float()\n",
    "middle = torch.arange(15,9, -1).float()\n",
    "\n",
    "pad_sequence([short, long, middle], batch_first=False)  # T x N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a0920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default value of batch_first in pad_sequence is False.\n",
    "# So you have to always be careful not to miss batch_first=True in pad_sequence, if you use batch_first=True for your RNN layer.\n",
    "pad_sequence([short, long, middle], batch_first=True)  # N x T "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5e0dd",
   "metadata": {},
   "source": [
    "1) However, the problem is that you can't figure out whether the 0 at the end of each sequence is a padded one, or was included in the original sequence\n",
    "- e.g. `[2, 3, 4, 3, 0]` becomes `[ 2,  3,  4,  5,  0,  0,  0]`. Now we don't know how many zeros were added for padding\n",
    "\n",
    "2) Also, if you run RNN for this padded sequence, RNN will calculate for the padded part also.\n",
    "- RNN doesn't know whether it is padded data, or existing data\n",
    "- This makes computation slower\n",
    "\n",
    "3) If you want to use bi-directional, which also reads the sequence from backward, paddings can make the result different.\n",
    "\n",
    "To solve this issue, we use PackedSequence, by using `pack_sequence`/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69086d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([27, 15,  3, 26, 14,  2, 25, 13,  1, 24, 12,  0, 23, 11, 22, 10, 21, 20]), batch_sizes=tensor([3, 3, 3, 3, 2, 2, 1, 1]), sorted_indices=tensor([1, 2, 0]), unsorted_indices=tensor([2, 0, 1]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_sequence = pack_sequence([short, long, middle], enforce_sorted=False)\n",
    "packed_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd50747",
   "metadata": {},
   "source": [
    "`PackedSequence` has `data` and `batch_sizes`\n",
    "- `data` contains the flattened value of given batch\n",
    "    - To optimize the computation, the sequences have to be sorted by descending of length\n",
    "- `batch_sizes` represents how many valid batch sample exists for each time step\n",
    "    - `[3, 3, 3, 2, 2, 1, 1]` means that there are 3 sequences for first three time steps, and then 2 sequences for next two steps, and then only 1 sequence for next two steps.\n",
    "- `sorted_indices` shows how the sorted sequences can be converted to original order.\n",
    "    - `[1,2,0]` means that \n",
    "        - the 0th sequence in the sorted sequences (the longest one) was indexed as 1 in the original input batch\n",
    "        - the 1st sequence in the sorted sequences (`middle`) was indexed as 2 in the original input batch\n",
    "        - the 2nd sequence in the sorted sequences (`short`) was index as 0 in the original input batch\n",
    "- `unsorted_indices` shows how the original sequences are sorted.\n",
    "    - `[2,0,1]` means that\n",
    "        - the 0th sequence in the original input was sorted as 2nd in the sorted sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0500f200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of output of RNN for PackedSequence: <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Type of last_hidden of RNN for PackedSequence: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "rnn_layer = nn.GRU(1, 1)\n",
    "packed_sequence = pack_sequence([short.unsqueeze(1), long.unsqueeze(1), middle.unsqueeze(1)], enforce_sorted=False)\n",
    "out, last_hidden = rnn_layer(packed_sequence)\n",
    "\n",
    "print(f\"Type of output of RNN for PackedSequence: {type(out)}\")\n",
    "print(f\"Type of last_hidden of RNN for PackedSequence: {type(last_hidden)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2e3e44",
   "metadata": {},
   "source": [
    "- RNN or its family of PyTorch can automatically handle `PackedSequence`\n",
    "- However, other layers like `nn.Embedding` or `nn.Linear` cannot take `PackedSequence` as its input\n",
    "- There are two ways to feed `PackedSequence` to these layers\n",
    "    - First, convert PackedSequence to ordinary torch.Tensor by `torch.nn.utils.rnn.pad_packed_sequence`\n",
    "        - This will convert PackedSequence to a tensor of sequneces with same length but different padding\n",
    "    - The other way is to feed only PackedSequence.data, and then declaring new PackedSequence with the output as `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08620c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This will make error, because other layers cannot handle PackedSequence\n",
    "'''\n",
    "test_linear_layer = nn.Linear(in_features=1, out_features=2)\n",
    "test_linear_layer(packed_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9efa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "One way to to this is using torch.nn.utils.rnn.pad_packed_sequence to convert PackedSequence to ordinary tensor\n",
    "'''\n",
    "\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "padded_sequence, batch_lengths = pad_packed_sequence(packed_sequence)\n",
    "print(f'The padded sequence generated from packed sequence (squeezed for printing): \\n {padded_sequence.squeeze()}')\n",
    "print(f'\"pad_packed_sequence\" also returns \"batch_lengths\", to clarify the original length before the padding: \\n {batch_lengths}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e302fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now you can feed padded sequence to linear layer.\n",
    "'''\n",
    "\n",
    "linear_output = test_linear_layer(padded_sequence)\n",
    "print(f\"Output of feeding padded_sequence to a linear layer: {linear_output}\")\n",
    "print(\"Caution that it returns non-zero values for timestep with zero padding, because linear layer has a bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "You can make the output as a PackedSequence, by using torch.nn.utils.rnn.pack_padded_sequence\n",
    "'''\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "re_packed_sequence = pack_padded_sequence(linear_output, batch_lengths, enforce_sorted=False)\n",
    "re_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22117c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Another way to do it is using PackedSequence.data\n",
    "'''\n",
    "\n",
    "linear_out_pack = test_linear_layer(packed_sequence.data)\n",
    "packed_sequence_after_linear = PackedSequence(linear_out_pack, packed_sequence.batch_sizes, packed_sequence.sorted_indices, packed_sequence.unsorted_indices)\n",
    "packed_sequence_after_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd119c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "357c61f4",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "![image](https://raw.githubusercontent.com/tensorflow/nmt/master/nmt/g3doc/img/seq2seq.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af0ca29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13ffb21b",
   "metadata": {},
   "source": [
    "## Define Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class Trainer:\n",
    "  def __init__(self, model, optimizer, loss_fn, train_loader, valid_loader, device):\n",
    "    self.model = model\n",
    "    self.optimizer = optimizer\n",
    "    self.loss_fn = loss_fn\n",
    "    self.train_loader = train_loader\n",
    "    self.valid_loader = valid_loader\n",
    "    \n",
    "    self.model.to(device)\n",
    "    \n",
    "    self.best_valid_accuracy = 0\n",
    "    self.device = device\n",
    "    \n",
    "    self.training_loss = []\n",
    "    self.validation_loss = []\n",
    "    self.validation_acc = []\n",
    "\n",
    "  def save_model(self, path='imdb_sentiment_model.pt'):\n",
    "    torch.save({'model':self.model.state_dict(), 'optim':self.optimizer.state_dict()}, path)\n",
    "    \n",
    "  def train_by_num_epoch(self, num_epochs):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "      self.model.train()\n",
    "      for batch in self.train_loader:\n",
    "        loss_value = self._train_by_single_batch(batch)\n",
    "        self.training_loss.append(loss_value)\n",
    "      self.model.eval()\n",
    "      validation_loss, validation_acc = self.validate()\n",
    "      self.validation_loss.append(validation_loss)\n",
    "      self.validation_acc.append(validation_acc)\n",
    "      \n",
    "      if validation_acc > self.best_valid_accuracy:\n",
    "        print(f\"Saving the model with best validation accuracy: Epoch {epoch+1}, Acc: {validation_acc:.4f} \")\n",
    "        self.save_model('imdb_sentiment_model_best.pt')\n",
    "      else:\n",
    "        self.save_model('imdb_sentiment_model_last.pt')\n",
    "      self.best_valid_accuracy = max(validation_acc, self.best_valid_accuracy)\n",
    "\n",
    "      \n",
    "  def _train_by_single_batch(self, batch):\n",
    "    '''\n",
    "    This method updates self.model's parameter with a given batch\n",
    "    \n",
    "    batch (tuple): (batch_of_input_text, batch_of_label)\n",
    "    \n",
    "    You have to use variables below:\n",
    "    \n",
    "    self.model (SentimentModel/torch.nn.Module): A neural network model\n",
    "    self.optimizer (torch.optim.adam.Adam): Adam optimizer that optimizes model's parameter\n",
    "    self.loss_fn (function): function for calculating BCE loss for a given prediction and target\n",
    "    self.device (str): 'cuda' or 'cpu'\n",
    "\n",
    "    output: loss (float): Mean binary cross entropy value for every sample in the training batch\n",
    "    The model's parameters, optimizer's steps has to be updated inside this method\n",
    "\n",
    "    TODO: Complete this method \n",
    "    '''\n",
    "\n",
    "    \n",
    "    return\n",
    "\n",
    "    \n",
    "  def validate(self, external_loader=None):\n",
    "    '''\n",
    "    This method calculates accuracy and loss for given data loader.\n",
    "    It can be used for validation step, or to get test set result\n",
    "    \n",
    "    input:\n",
    "      data_loader: If there is no data_loader given, use self.valid_loader as default.\n",
    "      \n",
    "    \n",
    "    output: \n",
    "      validation_loss (float): Mean Binary Cross Entropy value for every sample in validation set\n",
    "      validation_accuracy (float): Mean Accuracy value for every sample in validation set\n",
    "      \n",
    "    TODO: Complete this method \n",
    "\n",
    "    '''\n",
    "    \n",
    "    ### Don't change this part\n",
    "    if external_loader and isinstance(external_loader, DataLoader):\n",
    "      loader = external_loader\n",
    "      print('An arbitrary loader is used instead of Validation loader')\n",
    "    else:\n",
    "      loader = self.valid_loader\n",
    "      \n",
    "    self.model.eval()\n",
    "    \n",
    "    '''\n",
    "    Write your code from here, using loader, self.model, self.loss_fn.\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
