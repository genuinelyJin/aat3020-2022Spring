{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466d893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e6a9f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-11 10:50:58--  https://raw.githubusercontent.com/amephraim/nlp/master/texts/J.%20K.%20Rowling%20-%20Harry%20Potter%201%20-%20Sorcerer's%20Stone.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 439742 (429K) [text/plain]\n",
      "Saving to: ‘J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt.1’\n",
      "\n",
      "J. K. Rowling - Har 100%[===================>] 429.44K  1.14MB/s    in 0.4s    \n",
      "\n",
      "2022-04-11 10:50:59 (1.14 MB/s) - ‘J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt.1’ saved [439742/439742]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://raw.githubusercontent.com/amephraim/nlp/master/texts/J.%20K.%20Rowling%20-%20Harry%20Potter%201%20-%20Sorcerer's%20Stone.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fec6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(txt_path):\n",
    "  with open(txt_path, 'r') as f:\n",
    "    txt_string = f.readlines()\n",
    "  return txt_string\n",
    "\n",
    "corpus_string = read_txt(\"J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt\")\n",
    "corpus_string = \"\".join(corpus_string).replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47aab48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Harry Potter and the Sorcerer's Stone   CHAPTER ONE  THE BOY WHO LIVED  Mr. and Mrs. Dursley, of num\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_string[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e1f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "tokenizer(corpus_string)[:20]\n",
    "\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "vocab = build_vocab_from_iterator([tokenizer(corpus_string)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59a492da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "vocab = build_vocab_from_iterator([tokenizer(corpus_string)], specials=['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a86e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['harry', 'potter', 'and', 'the', 'sorcerer', \"'\", 's', 'stone', 'chapter', 'one', 'the', 'boy', 'who', 'lived', 'mr', '.', 'and', 'mrs', '.', 'dursley']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 126,\n",
       " 5,\n",
       " 3,\n",
       " 615,\n",
       " 4,\n",
       " 14,\n",
       " 158,\n",
       " 599,\n",
       " 48,\n",
       " 3,\n",
       " 150,\n",
       " 76,\n",
       " 1054,\n",
       " 155,\n",
       " 1,\n",
       " 5,\n",
       " 263,\n",
       " 1,\n",
       " 219]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_of_words = tokenizer(corpus_string)[:20]\n",
    "print(sequence_of_words)\n",
    "vocab(sequence_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a80132ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5959"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab size\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2495656",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msequence_of_words\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not float"
     ]
    }
   ],
   "source": [
    "sequence_of_words[0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d42dc8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   9,  126,    5,    3,  615,    4,   14,  158,  599,   48,    3,  150,\n",
       "           76, 1054,  155,    1,    5,  263,    1,  219]),\n",
       " tensor([[-1.0232, -1.3768,  0.3820, -0.5251],\n",
       "         [ 1.0945, -0.7239, -0.1121,  0.1413],\n",
       "         [ 0.1122,  0.2340,  0.0132, -0.8617],\n",
       "         [-1.0159,  2.4630,  0.9259,  0.8022],\n",
       "         [-0.8881,  0.2692, -1.8334,  0.3312],\n",
       "         [ 0.6817,  0.5533, -0.5790, -0.0400],\n",
       "         [-0.1536, -0.7923,  2.3783,  0.9355],\n",
       "         [ 0.9264, -0.9180,  2.0779, -0.5630],\n",
       "         [ 0.2727,  0.6659, -2.9204, -0.6824],\n",
       "         [ 0.4616, -1.1917, -1.8567, -0.9422],\n",
       "         [-1.0159,  2.4630,  0.9259,  0.8022],\n",
       "         [-0.5751, -0.1115,  0.2898, -0.4186],\n",
       "         [-1.0399,  0.3751, -0.3849, -0.8031],\n",
       "         [-1.8035, -2.1171, -0.4827, -2.9910],\n",
       "         [-0.7295, -0.3977,  0.8822,  0.6182],\n",
       "         [ 0.7147, -0.9582,  0.0986, -1.4691],\n",
       "         [ 0.1122,  0.2340,  0.0132, -0.8617],\n",
       "         [ 0.0645, -0.6192, -0.1381, -1.7604],\n",
       "         [ 0.7147, -0.9582,  0.0986, -1.4691],\n",
       "         [ 0.2696, -0.3475,  0.8714, -1.0724]], grad_fn=<EmbeddingBackward0>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb = nn.Embedding(len(vocab), 4)\n",
    "\n",
    "sentence_in_wrd_idx = vocab(sequence_of_words)\n",
    "sentence_in_wrd_idx = torch.LongTensor(sentence_in_wrd_idx)\n",
    "\n",
    "sentence_in_wrd_idx, word_emb(sentence_in_wrd_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "879d73b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 3\n",
    "\n",
    "weight_hh = nn.Linear(hidden_size, hidden_size)\n",
    "weight_hx = nn.Linear(4, hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e317a31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_hidden = torch.zeros(hidden_size)\n",
    "initial_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "900727a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current word is harry, and its embedding is tensor([-1.0232, -1.3768,  0.3820, -0.5251], grad_fn=<SelectBackward0>)\n",
      "Current word is potter, and its embedding is tensor([ 1.0945, -0.7239, -0.1121,  0.1413], grad_fn=<SelectBackward0>)\n",
      "Current word is and, and its embedding is tensor([ 0.1122,  0.2340,  0.0132, -0.8617], grad_fn=<SelectBackward0>)\n",
      "Current word is the, and its embedding is tensor([-1.0159,  2.4630,  0.9259,  0.8022], grad_fn=<SelectBackward0>)\n",
      "Current word is sorcerer, and its embedding is tensor([-0.8881,  0.2692, -1.8334,  0.3312], grad_fn=<SelectBackward0>)\n",
      "Current word is ', and its embedding is tensor([ 0.6817,  0.5533, -0.5790, -0.0400], grad_fn=<SelectBackward0>)\n",
      "Current word is s, and its embedding is tensor([-0.1536, -0.7923,  2.3783,  0.9355], grad_fn=<SelectBackward0>)\n",
      "Current word is stone, and its embedding is tensor([ 0.9264, -0.9180,  2.0779, -0.5630], grad_fn=<SelectBackward0>)\n",
      "Current word is chapter, and its embedding is tensor([ 0.2727,  0.6659, -2.9204, -0.6824], grad_fn=<SelectBackward0>)\n",
      "Current word is one, and its embedding is tensor([ 0.4616, -1.1917, -1.8567, -0.9422], grad_fn=<SelectBackward0>)\n",
      "Current word is the, and its embedding is tensor([-1.0159,  2.4630,  0.9259,  0.8022], grad_fn=<SelectBackward0>)\n",
      "Current word is boy, and its embedding is tensor([-0.5751, -0.1115,  0.2898, -0.4186], grad_fn=<SelectBackward0>)\n",
      "Current word is who, and its embedding is tensor([-1.0399,  0.3751, -0.3849, -0.8031], grad_fn=<SelectBackward0>)\n",
      "Current word is lived, and its embedding is tensor([-1.8035, -2.1171, -0.4827, -2.9910], grad_fn=<SelectBackward0>)\n",
      "Current word is mr, and its embedding is tensor([-0.7295, -0.3977,  0.8822,  0.6182], grad_fn=<SelectBackward0>)\n",
      "Current word is ., and its embedding is tensor([ 0.7147, -0.9582,  0.0986, -1.4691], grad_fn=<SelectBackward0>)\n",
      "Current word is and, and its embedding is tensor([ 0.1122,  0.2340,  0.0132, -0.8617], grad_fn=<SelectBackward0>)\n",
      "Current word is mrs, and its embedding is tensor([ 0.0645, -0.6192, -0.1381, -1.7604], grad_fn=<SelectBackward0>)\n",
      "Current word is ., and its embedding is tensor([ 0.7147, -0.9582,  0.0986, -1.4691], grad_fn=<SelectBackward0>)\n",
      "Current word is dursley, and its embedding is tensor([ 0.2696, -0.3475,  0.8714, -1.0724], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_seq = word_emb(sentence_in_wrd_idx)\n",
    "input_seq.shape\n",
    "hidden = torch.zeros(hidden_size)\n",
    "\n",
    "total_hidden = [] \n",
    "for i in range(len(input_seq)):\n",
    "  print(f'Current word is {sequence_of_words[i]}, and its embedding is {input_seq[i]}')\n",
    "  hh_value = weight_hh(hidden)\n",
    "  hx_value = weight_hx(input_seq[i])\n",
    "  \n",
    "  hhx_value = hh_value + hx_value\n",
    "  hidden = torch.tanh(hhx_value)\n",
    "  total_hidden.append(hidden)\n",
    "  \n",
    "#   hx_value = weight_hx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb3a25db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3305, -0.8447, -0.7648], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_hidden)\n",
    "\n",
    "total_hidden[0] # hidden state after we have read 0th word, harry\n",
    "\n",
    "total_hidden[7] # hidden state after we have read until 7th word, harry potter and the socerer ' s stone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ff0154a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7bd5ebd7f0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_hidden_tensor = torch.stack(total_hidden)\n",
    "total_hidden_tensor.shape\n",
    "\n",
    "plt.imshow(total_hidden_tensor.detach().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "def09066",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8890e-04, 1.0490e-04, 3.2936e-04,  ..., 1.2484e-04, 1.2365e-04,\n",
       "         1.0404e-04],\n",
       "        [2.6241e-04, 1.2361e-04, 2.9889e-04,  ..., 1.2628e-04, 1.1300e-04,\n",
       "         1.5770e-04],\n",
       "        [1.8033e-04, 1.3745e-04, 2.5466e-04,  ..., 1.1655e-04, 1.1684e-04,\n",
       "         1.1778e-04],\n",
       "        ...,\n",
       "        [1.3979e-04, 9.0500e-05, 3.1964e-04,  ..., 1.3082e-04, 1.3350e-04,\n",
       "         6.8426e-05],\n",
       "        [1.8460e-04, 8.8961e-05, 3.7239e-04,  ..., 1.2758e-04, 1.2671e-04,\n",
       "         9.2438e-05],\n",
       "        [2.0124e-04, 1.1976e-04, 3.0805e-04,  ..., 1.1527e-04, 1.1602e-04,\n",
       "         1.2458e-04]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_to_vocab = nn.Linear(hidden_size, len(vocab))\n",
    "\n",
    "vocab_logit = hidden_to_vocab(total_hidden_tensor)\n",
    "vocab_prob = torch.softmax(vocab_logit, dim=-1)\n",
    "vocab_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcdca1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "021385d0",
   "metadata": {},
   "source": [
    "## New start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34311cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtext.vocab import build_vocab_from_iterator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b3777c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(txt_path):\n",
    "  with open(txt_path, 'r') as f:\n",
    "    txt_string = f.readlines()\n",
    "  return txt_string\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de7f26c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  12,   11,  834,    6,   39,    1,    3,  240, 2363,    6,  104,   34,\n",
       "           3, 2993,  118,  168,   51,    3,  899,  598,   15,    3,  503,    1,\n",
       "           3,  240,  195,   24,    3,  899,   22,    8,  362, 1074,    2,  130,\n",
       "           2,   29,   23,   22,  100,  124,  230,   28,    1,   50,  150,   11,\n",
       "         218,  152,  483,   37,  959,    3,  899,  180,   23,   63,    4,   18,\n",
       "         171,   93, 2969,   32,    8, 2612,   67,   24,    1,   75,  155,    1,\n",
       "           5,  263,    1,  219, 1014,   38,   25,    3, 2733,    2,  882, 2451,\n",
       "         290,  912, 2404,    2,   41,   11,  224,   55,    3, 2633,  785,  324,\n",
       "           6, 1944,   24,  486,    5, 1412,  228,  118,  726,   39, 1790,   33,\n",
       "          80,    3, 1723,    1,  155,    1,  219, 2200,   27,    7,  641,   35,\n",
       "          16,  376, 2036, 5664,   37,  401,    2,    5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextSet:\n",
    "  def __init__(self, txt_path, batch_len=10):\n",
    "    corpus_string = read_txt(txt_path)\n",
    "    self.corpus_string = \"\".join(corpus_string).replace('\\n', ' ')\n",
    "    self.vocab = build_vocab_from_iterator([tokenizer(self.corpus_string)], specials=['<unk>'])\n",
    "    self.corpus_in_word_tokens = tokenizer(self.corpus_string)\n",
    "    self.corpus_in_idx_tokens = self.vocab(self.corpus_in_word_tokens)\n",
    "    \n",
    "    self.batch_len = batch_len\n",
    "    self.batchify_corpus()\n",
    "    \n",
    "  def batchify_corpus(self):\n",
    "    self.corpus_in_idx_tokens = self.corpus_in_idx_tokens[:len(self.corpus_in_idx_tokens)//self.batch_len*self.batch_len]\n",
    "    self.batch_tensor = torch.LongTensor(self.corpus_in_idx_tokens)\n",
    "    self.batch_tensor = self.batch_tensor.reshape(-1, self.batch_len)\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.batch_tensor)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    return self.batch_tensor[idx]\n",
    "  \n",
    "dataset = TextSet(\"J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt\", batch_len=128)\n",
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f026beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "  def __init__(self, vocab_size, hidden_size):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.word_encoder = nn.Embedding(vocab_size, hidden_size)\n",
    "    self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
    "    self.word_prob_decoder = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    word_vecs = self.word_encoder(x)\n",
    "    hidden_states, _ = self.rnn(word_vecs)\n",
    "    word_prob_logit = self.word_prob_decoder(hidden_states)\n",
    "    word_prob = torch.softmax(word_prob_logit, dim=-1)\n",
    "    return word_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95497cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128, 5959])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "model = LanguageModel(len(dataset.vocab), 64)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "output = model(batch)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71fc60b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for batch in train_loader:\n",
    "    out = model(batch.cuda())\n",
    "    \n",
    "    out_flatten = out.reshape(-1, out.shape[-1])\n",
    "    true_word = batch[:, 1:]\n",
    "    \n",
    "    break\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b94bc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 128, 5959]), torch.Size([2048, 5959]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, out_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "857ce46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1965,  139,  592,  ...,   22, 3163,   38],\n",
       "        [   6, 3828,   20,  ...,  454,  143,    1],\n",
       "        [  22,    6, 2116,  ...,  371,   12,  838],\n",
       "        ...,\n",
       "        [ 184,    2,   13,  ..., 4679,   27,   23],\n",
       "        [  19,  816, 2891,  ...,   38,   15, 1026],\n",
       "        [  39,  301,    3,  ...,    2,    9,  199]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "803111a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 139,  592,  485,  ...,   22, 3163,   38],\n",
       "        [3828,   20,    7,  ...,  454,  143,    1],\n",
       "        [   6, 2116,    9,  ...,  371,   12,  838],\n",
       "        ...,\n",
       "        [   2,   13,    4,  ..., 4679,   27,   23],\n",
       "        [ 816, 2891,    1,  ...,   38,   15, 1026],\n",
       "        [ 301,    3, 1548,  ...,    2,    9,  199]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d25a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class VanillaRNN(nn.Module):\n",
    "  def __init__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
