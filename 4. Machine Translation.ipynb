{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2542ef",
   "metadata": {},
   "source": [
    "# Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666482a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1CpsqOuuuB3I_PG5DbuqH1ssCFVerU46g\n",
      "To: /home/teo/userdata/sg-aat-3020/aat3020-2022Spring/nia-aihub-korean-english.zip\n",
      "100%|████████████████████████████████████████| 276M/276M [00:34<00:00, 8.06MB/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Download dataset (originally from NIA AI-Hub)\n",
    "'''\n",
    "\n",
    "!gdown 1CpsqOuuuB3I_PG5DbuqH1ssCFVerU46g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q nia-aihub-korean-english.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791db281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = Path('/home/teo/userdata/datasets/nia_korean_english')\n",
    "# list(dataset_dir.glob('*.xlsx'))\n",
    "for xlsx in dataset_dir.glob('*.xlsx'):\n",
    "  df = pd.read_excel(path)\n",
    "  kor_text_path = path.parent / (path.stem+'_kor.txt') \n",
    "  eng_text_path = path.parent / (path.stem+'_eng.txt') \n",
    "  with open(kor_text_path, 'w', encoding='utf8') as f:\n",
    "      f.write('\\n'.join(df['원문']))\n",
    "  with open(eng_text_path, 'w', encoding='utf8') as f:\n",
    "      f.write('\\n'.join(df['번역문']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a2e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abc115cd",
   "metadata": {},
   "source": [
    "## Huggingface Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee3c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "tokenizer = BertWordPieceTokenizer(strip_accents=False, lowercase=False)\n",
    "\n",
    "corpus_file   = [str(eng_text_path)]  \n",
    "vocab_size    = 32000  \n",
    "limit_alphabet= 6000  \n",
    "output_dir   = Path('hugging_eng_%d'%(vocab_size))\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "min_frequency = 5 \n",
    "\n",
    "tokenizer.train(files=corpus_file,\n",
    "               vocab_size=vocab_size,\n",
    "               min_frequency=min_frequency,\n",
    "               limit_alphabet=limit_alphabet, \n",
    "               show_progress=True)\n",
    "\n",
    "tokenizer.save_model(str(output_dir))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
